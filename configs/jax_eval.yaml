# JAX evaluation configuration for CatGPT
# Override values via CLI: uv run python scripts/evaluate_jax.py compute.matmul_precision=highest
#
# Usage:
#   # Run with defaults
#   uv run python scripts/evaluate_jax.py
#
#   # Override checkpoint path
#   uv run python scripts/evaluate_jax.py checkpoint=checkpoints_jax/epoch_50
#
#   # Use MCTS engine with custom simulations
#   uv run python scripts/evaluate_jax.py engine.type=mcts engine.mcts.num_simulations=1600
#
#   # Run on all benchmarks
#   uv run python scripts/evaluate_jax.py benchmark.names=[puzzles,high_rated_puzzles]
#
#   # Quick test with fewer puzzles
#   uv run python scripts/evaluate_jax.py benchmark.max_puzzles=100

# Checkpoint to evaluate
checkpoint: "checkpoints_jax/best/best"

# Engine configuration
engine:
  type: "mcts"  # Options: "value", "policy", "mcts"
  batch_size: 1

  # MCTS-specific settings (only used when type=mcts)
  mcts:
    num_simulations: 400
    c_puct: 1.4
    fpu_value: -1.0  # First play urgency (-1 = assume loss for unvisited)

# Benchmark configuration
benchmark:
  names:
    - "puzzles"  # Default benchmark
  # Available benchmarks: "puzzles", "high_rated_puzzles"
  # Use names: ["puzzles", "high_rated_puzzles"] for all
  max_puzzles: 10000  # null for unlimited
  puzzles_path: "puzzles/puzzles.csv"
  high_rated_puzzles_path: "puzzles/high_rated_puzzles.csv"

# Compute configuration
compute:
  matmul_precision: "high"  # Options: "high" (TF32 on Ampere+), "highest" (full float32)
  compute_dtype: "bfloat16"  # Options: "float32", "float16", "bfloat16"

# Weights & Biases logging
wandb:
  enabled: true
  project: "catgpt-puzzles"
  entity: null  # Your W&B username or team
  tags:
    - "eval"

# Logging
verbose: false
